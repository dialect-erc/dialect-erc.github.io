---
---

@inproceedings{blaschke-etal-2023-survey,
    teaser="This paper provides an overview of more than 80 corpora to support NLP research in resource-poor and non-standardized languages of the Germanic language family.",
    image = "GerLowResourceVarieties.png",
    title = "A Survey of Corpora for {G}ermanic Low-Resource Languages and Dialects",
    author = "Blaschke, Verena  and
      Schuetze, Hinrich  and
      Plank, Barbara",
    editor = {Alum{\"a}e, Tanel  and
      Fishel, Mark},
    booktitle = "Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)",
    month = may,
    year = "2023",
    address = "T{\'o}rshavn, Faroe Islands",
    publisher = "University of Tartu Library",
    url = "https://aclanthology.org/2023.nodalida-1.41",
    pages = "392--414",
    abstract = "Despite much progress in recent years, the vast majority of work in natural language processing (NLP) is on standard languages with many speakers. In this work, we instead focus on low-resource languages and in particular non-standardized low-resource languages. Even within branches of major language families, often considered well-researched, little is known about the extent and type of available resources and what the major NLP challenges are for these language varieties. The first step to address this situation is a systematic survey of available corpora (most importantly, annotated corpora, which are particularly valuable for NLP research). Focusing on Germanic low-resource language varieties, we provide such a survey in this paper. Except for geolocation (origin of speaker or document), we find that manually annotated linguistic resources are sparse and, if they exist, mostly cover morphosyntax. Despite this lack of resources, we observe that interest in this area is increasing: there is active development and a growing research community. To facilitate research, we make our overview of over 80 corpora publicly available.",
}

@misc{wang2024my,
      teaser="This paper investigates to what extent the first token probabilities of large language models match their final answers to multiple-choice questions.",
      url= "https://arxiv.org/abs/2402.14499",
      image = "first-token-prob.png",
      title={"My Answer is C": First-Token Probabilities Do Not Match Text Answers in Instruction-Tuned Language Models}, 
      author={Xinpeng Wang and Bolei Ma and Chengzhi Hu and Leon Weber-Genzel and Paul RÃ¶ttger and Frauke Kreuter and Dirk Hovy and Barbara Plank},
      year={2024},
      month=feb,
      eprint={2402.14499},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@inproceedings{litschko-etal-2023-establishing,
    image = "establishing_trustworthiness.png",
    teaser = "Decades of NLP research have traditionally compartmentalized linguistic tasks, but the emergence of large language models is reshaping this approach, emphasizing the need for holistic, task-agnostic evaluation methods that prioritize trustworthiness.",
    title = "Establishing Trustworthiness: Rethinking Tasks and Model Evaluation",
    author = {Litschko, Robert  and
      M{\"u}ller-Eberstein, Max  and
      van der Goot, Rob  and
      Weber-Genzel, Leon  and
      Plank, Barbara},
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.14",
    doi = "10.18653/v1/2023.emnlp-main.14",
    pages = "193--203",
    abstract = "Language understanding is a multi-faceted cognitive capability, which the Natural Language Processing (NLP) community has striven to model computationally for decades. Traditionally, facets of linguistic intelligence have been compartmentalized into tasks with specialized model architectures and corresponding evaluation protocols. With the advent of large language models (LLMs) the community has witnessed a dramatic shift towards general purpose, task-agnostic approaches powered by generative models. As a consequence, the traditional compartmentalized notion of language tasks is breaking down, followed by an increasing challenge for evaluation and analysis. At the same time, LLMs are being deployed in more real-world scenarios, including previously unforeseen zero-shot setups, increasing the need for trustworthy and reliable systems. Therefore, we argue that it is time to rethink what constitutes tasks and model evaluation in NLP, and pursue a more holistic view on language, placing trustworthiness at the center. Towards this goal, we review existing compartmentalized approaches for understanding the origins of a model{'}s functional capacity, and provide recommendations for more multi-faceted evaluation protocols.",
}